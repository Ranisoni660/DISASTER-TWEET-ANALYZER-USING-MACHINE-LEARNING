# -*- coding: utf-8 -*-
"""REAL_OR_FAKE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18jMkukGCU4c_BA0TTErREa9u_2-gCupC
"""

import pandas as pd
import numpy as np

# Load your dataset
df = pd.read_csv('/content/twittertweets_dataset.csv')

# Function to predict real vs fake tweets
def predict_real_tweet(text):
    fake_indicators = [
        'BREAKING' in text,
        'URGENT' in text,
        'CLICK HERE' in text,
        'READ MORE' in text,
        'VISIT NOW' in text,
        any(word in text.lower() for word in ['fake', 'hoax', 'scam', 'phishing', 'malware', 'enjoying', 'reading', 'shopping', 'exploring', 'attending', 'amazing', 'sunny', 'downtown', 'cozy', 'weekend', 'fun']),
        any(url in text for url in ['https://t.co/0gL7NUCPlb https://t.co/u1CcBhOWh9', 'https://t.co/99uHGAzxy2', 'https://t.co/rhzOMQVSlj']),
        text.count('#') > 5,
        text.count('@') > 5,
        len(text) < 20,
        text.isupper(),
        'RETWEET' in text.upper(),
        'SHARE' in text.upper(),
        text.count('!') > 3
    ]
    real_indicators = [
        any(city in text for city in ['New Delhi', 'Mumbai', 'Hyderabad', 'Bengaluru', 'Kolar']),
        any(word in text for word in ['humanitarian', 'aid', 'crisis', 'management'])
    ]

    score = sum(1 for indicator in real_indicators if indicator) - sum(1 for indicator in fake_indicators if indicator)

    return 1 if score >= 1 else 0
# Apply function to predict Target2
df['target2'] = np.where(df['target'] == 0, 0, df['text'].apply(predict_real_tweet))

# Save updated DataFrame to CSV
df.to_csv('twitter_tweets_updated.csv', index=False)

def predict_real_tweet(text):
    fake_indicators = [
        # Sensational language
        'BREAKING' in text,
        'URGENT' in text,
        'CLICK HERE' in text,
        'READ MORE' in text,
        'VISIT NOW' in text,
        'CONGRATULATIONS' in text,
        'WINNER' in text,
        'TICKETS ON SALE!!!' in text,
        # Common spam keywords
        any(word in text.lower() for word in [
            'fake', 'hoax', 'scam', 'phishing', 'malware',
            'enjoying', 'reading', 'shopping', 'exploring', 'attending',
            'amazing', 'sunny', 'downtown', 'cozy', 'weekend', 'fun'
        ]),
        # Excessive hashtags or mentions
        text.count('#') > 5,
        text.count('@') > 5,
        # Very short tweets
        len(text) < 10,
        len(text) < 20,
        # All caps
        text.isupper(),
        # Calls to action
        'RETWEET' in text.upper(),
        'SHARE' in text.upper(),
        # Excessive punctuation
        text.count('!') > 3,
        # Geographic locations with potential conflict
        'Iran' in text
    ]

    real_indicators = [
        # Specific cities or states
        any(city in text for city in [
            'New Delhi', 'Mumbai', 'Hyderabad', 'Bengaluru', 'Kolar',
            'New York', 'Los Angeles', 'Chicago', 'Houston'
        ]),
        # Countries
        any(country in text for country in [
            'United States', 'India', 'China', 'Japan', 'Germany'
        ]),
        # Humanitarian or crisis-related keywords
        any(word in text for word in [
            'humanitarian', 'aid', 'crisis', 'management','Taal volcano erupts','Violent Storm Force','wild','extreme', 'violent','Shipping forecast tonight',
            'earthquake', 'Puerto Rico', 'seismic', 'quake', 'tsunami','donated','Volcanic eruptions','wild fire','#Brazil','Praying','FIRES GONE WILD','Heartbreaking',
            'flood', 'Flash Flood Warning', 'rain', 'landslide', 'volcano','Wildfire','South Koreas Eastern Coast','disastrous',' Australian fire relief',
            'Philippines', 'thunderstorm', 'lightning','wildfires','Australia wildfire relief','Australia','wildfire relief','#wildfire','Australian Animals',' Wildfire Disaster','billion animals','Donation'
        ]),
        # Magnitude or aftershock mentions
        'magnitude' in text.lower() or 'aftershock' in text.lower()
    ]

    score = sum(1 for indicator in real_indicators if indicator) - sum(1 for indicator in fake_indicators if indicator)
    return 1 if score >= 1 else 0

# Apply function to predict Target2
df['target2'] = np.where(df['target'] == 0, 0, df['text'].apply(predict_real_tweet))
# Save updated DataFrame to CSV
df.to_csv('twitter_tweets_final1.csv', index=False)

# Load the updated CSV file
df_updated = pd.read_csv('twitter_tweets_final1.csv')

# Print the first few rows of the updated DataFrame
print(df_updated.head())

# Check the shape of the updated DataFrame
print("Updated DataFrame shape:", df_updated.shape)

print(df_updated['target2'].value_counts())

# Get the predicted probabilities
predictions = df['text'].apply(predict_real_tweet)
# Print the count of each predicted values
print(predictions.value_counts())

# Predicted real tweets
real_tweets = df[df['target2'] == 1]
# Print the first few rows
print(real_tweets.head())

# Predicted real tweets
fake_tweets = df[df['target2'] == 0]
print(fake_tweets.head(40))

# Save to CSV
fake_tweets.to_csv('predicted_fake_tweets1.csv', index=False)

#Save to CSV
real_tweets.to_csv('predicted_real_tweets1.csv', index=False)

