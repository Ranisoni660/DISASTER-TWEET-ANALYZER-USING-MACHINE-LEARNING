# -*- coding: utf-8 -*-
"""FINAL_DATASET_CREATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AA9mrx1ZjzxI9HyXSMR_S-FcZWOm0BaO
"""

import pandas as pd
import numpy as np

# Load your dataset
df = pd.read_csv('/content/twittertweets_dataset.csv',encoding='latin1')
# Load your dataset
df2 = pd.read_csv('/content/train_data_cleaning2.csv')

# Get unique values and counts
print(df['keyword'].value_counts())

# Get unique values and counts
keyword_counts = df['keyword'].value_counts()
# Print the results
print(keyword_counts.to_frame('count'))

# Get unique values
unique_keywords = df['keyword'].unique()
# Print the results
print(unique_keywords)

# Define keywords to remove
keywords_to_remove = [
    'suicide%20bomb', 'suicide%20bomber', 'suicide%20bombing',
    'battle', 'wreck', 'wreckage', 'wrecked','screamed', 'screaming',
    'bomb', 'bombed', 'bombing','hijack','avalanche','casualties', 'casualty',
       'hijacker', 'hijacking','annihilated', 'annihilation',
    'ablaze', 'accident', 'airplane%20accident',
    'terrorism', 'terrorist', 'army','body%20bag','blew%20up', 'blight', 'blizzard', 'blood',
       'bloody', 'blown%20up','bioterror', 'bioterrorism',
    'body%20bag', 'body%20bagging', 'body%20bags','body%20bag','airplane%20accident','sirens',
]
# Define the tweet to keep
tweet_to_keep = "Grandmotherâ€™s prayer closet survives powerful tornado that flattened home, killed many (link unavailable)"

# Filter out tweets containing 'flattened' keyword except the specified tweet
df_filtered = df[~((df['keyword'] == 'flattened') & (df['text'] != tweet_to_keep))]
# Convert keywords to lowercase
keywords_to_remove = [keyword.lower() for keyword in keywords_to_remove]
# Filter out tweets containing keywords to remove
df_filtered = df[~df['keyword'].str.lower().isin(keywords_to_remove) &
                 ~df['text'].str.lower().str.contains('|'.join(keywords_to_remove))]

df_filtered['keyword'].unique()

df.shape

df_filtered.shape

# Calculate keyword frequencies
keyword_freq = df_filtered['keyword'].value_counts()
# Print top 20 keywords
print(keyword_freq.nlargest(30))

# Get unique values for dataset 2
unique_keywords2 = df2['keyword'].unique()
# Print the results
print(unique_keywords2)

# Calculate keyword frequencies
keyword_freq2 = df2['keyword'].value_counts()
# Print top 20 keywords
print(keyword_freq2.nlargest(30))

# Define disaster-related keywords
disaster_keywords = [
    'violent%20storm', 'volcano', 'earthquake', 'thunder', 'thunderstorm',
    'tornado', 'landslide', 'lava', 'lightning', 'flood', 'flooding',
    'floods', 'forest%20fire', 'forest%20fires', 'natural%20disaster',
    'cyclone', 'obliterate', 'obliterated', 'sandstorm', 'burned',
    'burning', 'burning%20buildings', 'bush%20fires', 'nuclear%20disaster',
    'hazardous', 'heat%20wave', 'hellfire'
]
# Convert keywords to lowercase
disaster_keywords = [keyword.lower() for keyword in disaster_keywords]
# Filter df2 for disaster-related keywords
df2_disaster = df2[df2['keyword'].str.lower().isin(disaster_keywords)]
# Merge df2_disaster with df_filtered
df_merged = pd.concat([df_filtered, df2_disaster], ignore_index=True)
# Reset index
df_merged.reset_index(drop=True, inplace=True)

df_merged.shape

df_merged['keyword'].unique()

df_merged['target'].value_counts()

# Define new tweets
new_tweets = [
    "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all",
    "Forest fire near La Ronge Sask . Canada",
    "All residents asked to ' shelter in place ' are being notified by officers . No other evacuation or shelter in place orders are expected",
    "13,000 people receive #wildfire evacuation orders in California",
    "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school",
    "#Rocky Fire Update = > California Hwy . 20 closed in both directions due to Lake County fire - #CAfire #wildfires",
    "#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas",
    "I am on top of the hill and I can see a fire in the woods .There is an emergency evacuation happening now in the building across the street",
    "I am afraid that the tornado is coming to our area .",
    "Three people died from the heat wave so far",
    "Haha South Tampa is getting flooded hah - WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding",
    "#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days . I have lost count",
    "#Flood in Bago Myanmar # We arrived Bago",
    "Damage to school bus on 80 in multi car crash #BREAKING",
    "Breaking: Hurricane warning issued for Florida's east coast! Evacuation ordered #hurricane #disaster",
"Just witnessed a massive landslide in Colorado! Multiple casualties reported #landslide #emergency",
"Wildfire spreads rapidly in California, thousands evacuated #wildfire #california",
"Flood alert issued for downtown Chicago after heavy rainfall #flood #chicago",
"Tornado touches down in Oklahoma, widespread damage reported #tornado #oklahoma",
"Cyclone Idai makes landfall in Mozambique, thousands displaced #cyclone #mozambique",
"Earthquake magnitude 7.5 hits Indonesia, tsunami warning issued #earthquake #indonesia",
"Emergency declared in New York City due to severe snowstorm #blizzard #nyc",
"Deadly wildfire sweeps through Greek island of Evia #wildfire #greece",
"Flash flooding in Paris after heavy rainfall #flood #paris",
"Hurricane Dorian strengthens to Category 5 #hurricane #dorian",
"Landslide blocks major highway in Nepal #landslide #nepal",
"Wildfire forces evacuation of entire town in Australia #wildfire #australia",
"Floods inundate Venice, Italy #flood #venice",
"Tornado outbreak hits southern United States #tornado #usa",
"Cyclone Fani makes landfall in India, widespread destruction reported #cyclone #india",
"Earthquake hits Japan, tsunami warning issued #earthquake #japan",
"Severe drought affects millions in Africa #drought #africa",
"Wildfire burns thousands of acres in Spain #wildfire #spain",
"Flash flooding in Houston after heavy rainfall #flood #houston",
"Landslide kills dozens in Colombia #landslide #colombia",
"Hurricane Maria devastates Puerto Rico #hurricane #maria",
"Cyclone Idai affects millions in southern Africa #cyclone #idai",
"Earthquake hits Mexico City, buildings damaged #earthquake #mexico",
"Wildfire forces evacuation of Los Angeles neighborhood #wildfire #losangeles",
"Flood warning issued for River Seine in Paris #flood #paris",
"Tornado touches down in Kansas #tornado #kansas",
"Heat wave kills dozens in India #heatwave #india",
"Landslide blocks river in China #landslide #china",
"Wildfire burns hundreds of homes in California #wildfire #california",
"Flash flooding in North Carolina after heavy rainfall #flood #northcarolina",
"Cyclone Trevor hits northern Australia #cyclone #australia",
"Earthquake magnitude 6.8 hits Alaska #earthquake #alaska",
"Severe storm hits Europe #storm #europe",
"Wildfire forces evacuation of Canadian town #wildfire #canada",
"Landslide kills dozens in Indonesia #landslide #indonesia",
"Flood warning issued for Venice #flood #venice",
"Tornado outbreak hits Midwest United States #tornado #midwest",
"Cyclone Phethai makes landfall in India #cyclone #india",
"Earthquake hits Philippines #earthquake #philippines",
"Wildfire burns thousands of acres in Portugal #wildfire #portugal",
"Flash flooding in Texas after heavy rainfall #flood #texas",
"Landslide blocks major highway in California #landslide #california",
"Hurricane Lorenzo strengthens to Category 5 #hurricane #lorenzo",
"Wildfire forces evacuation of Greek island #wildfire #greece",
"Flood warning issued for River Thames in London #flood #london",
"Tornado touches down in Tennessee #tornado #tennessee",
"Cyclone Kenneth makes landfall in Mozambique #cyclone #mozambique",
"Earthquake magnitude 7.2 hits Papua New Guinea #earthquake #png",
"Wildfire burns hundreds of homes in South Africa #wildfire #southafrica",
"Emergency declared in California due to wildfires #wildfire #california",
"Tornado warning issued for multiple counties in Alabama #tornado #alabama",
"Floods displace thousands in Bangladesh #flood #bangladesh",
"Earthquake magnitude 6.5 hits Chile #earthquake #chile",
"Hurricane warning issued for Hawaii #hurricane #hawaii",
"Wildfire forces evacuation of town in Canada #wildfire #canada",
"Landslide blocks major highway in India #landslide #india",
"Flash flooding in China after heavy rainfall #flood #china",
"Cyclone Fani affects millions in India #cyclone #india",
"Tornado touches down in Missouri #tornado #missouri",
"Wildfire burns thousands of acres in Australia #wildfire #australia",
"Earthquake hits Turkey, multiple casualties reported #earthquake #turkey",
"Flood warning issued for River Mississippi #flood #mississippi",
"Hurricane Dorian makes landfall in North Carolina #hurricane #dorian",
"Wildfire forces evacuation of Los Angeles neighborhood #wildfire #losangeles",
"Landslide kills dozens in Nepal #landslide #nepal",
"Flash flooding in Indonesia after heavy rainfall #flood #indonesia",
"Cyclone Idai makes landfall in Zimbabwe #cyclone #zimbabwe",
"Tornado outbreak hits southern United States #tornado #usa",
"Wildfire burns hundreds of homes in South Africa #wildfire #southafrica",
"Earthquake magnitude 7.1 hits Philippines #earthquake #philippines",
"Floods inundate Venice, Italy #flood #venice",
"Hurricane Lorenzo strengthens to Category 5 #hurricane #lorenzo",
"Wildfire forces evacuation of Greek island #wildfire #greece",
"Tornado touches down in Kansas #tornado #kansas",
"Emergency declared in New York City due to severe snowstorm #blizzard #nyc",
"Wildfire burns thousands of acres in Spain #wildfire #spain",
"Flash flooding in Paris after heavy rainfall #flood #paris",
"Landslide blocks major highway in California #landslide #california",
"Hurricane Maria devastates Puerto Rico #hurricane #maria",
"Cyclone Phethai makes landfall in India #cyclone #india",
"Earthquake hits Japan, tsunami warning issued #earthquake #japan",
"Wildfire forces evacuation of Canadian town #wildfire #canada",
"Flash flooding in Texas after heavy rainfall #flood #texas",
"Tornado outbreak hits Midwest United States #tornado #midwest",
"Wildfire burns hundreds of homes in California #wildfire #california",
"Earthquake magnitude 6.8 hits Alaska #earthquake #alaska",
"Severe storm hits Europe #storm #europe",
"Landslide kills dozens in Indonesia #landslide #indonesia",
"Flood warning issued for Venice #flood #venice",
"Hurricane Dorian makes landfall in Bahamas #hurricane #dorian",
"Wildfire forces evacuation of town in Australia #wildfire #australia"
]

# Create DataFrame with new tweets
new_df = pd.DataFrame({
    'text': new_tweets,
    'target': [1]*len(new_tweets),
    'location': ['']*len(new_tweets),
    'id': [i for i in range(len(new_tweets))],
    'keyword': ['disaster']*len(new_tweets)
})
# Merge new_df with df_merged
df_merged = pd.concat([df_merged, new_df], ignore_index=True)

# Reset index
df_merged.reset_index(drop=True, inplace=True)

df_merged.shape

df_merged['target'].value_counts()

# Define disaster-related keywords and phrases
disaster_keywords = ['earthquake', 'flood', 'wildfire', 'hurricane', 'tornado', 'landslide', 'cyclone']
disaster_phrases = ['evacuation ordered', 'emergency declared', 'multiple casualties', 'widespread damage', 'rescue operations underway']

# Generate 500 new tweets
new_tweets = []
for i in range(800):
    keyword = np.random.choice(disaster_keywords)
    phrase = np.random.choice(disaster_phrases)
    location = np.random.choice(['USA', 'Europe', 'Asia', 'Africa', 'South America',"Republic of Philippines", "China", "England", "Malaysia", "Johannesburg, South Africa",
"Indonesia", "Dublin, Ireland", "Portland", "Pennsylvania", "Pakistan", "Israel",
"Mumbai, India", "Kenya", "Bangkok, Thailand", "Los Angeles",
"Cape Town, South Africa", "Tokyo, Japan", "Manila, Philippines", "New Orleans",
"Jakarta, Indonesia", "Mexico City, Mexico", "Bengaluru, India", "San Francisco",
"Nairobi, Kenya", "Kolkata, India", "Caribbean Islands", "Southeast Asia",
"California", "New York", "Bangladesh", "Sri Lanka", "Vietnam", "Cambodia",
"Thailand", "Myanmar", "Nepal", "Tanzania", "Ethiopia", "Ghana", "Uganda",
"South Korea", "Taiwan", "Singapore", "New Zealand", "Fiji", "Samoa", "Tonga"])
    tweet = f"Breaking: {keyword} hits {location}! {phrase} #disaster #emergency"
    new_tweets.append(tweet)

# Create DataFrame with new tweets
new_df2 = pd.DataFrame({
    'text': new_tweets,
    'target': [1]*len(new_tweets),
    'location': [np.random.choice(['Europe', 'Asia', 'Africa', 'South America','New york','iran',"Texas", "Washington D.C.", "Florida", "Hong Kong, China",
"Republic of Philippines", "China", "England", "Malaysia", "Johannesburg, South Africa",
"Indonesia", "Dublin, Ireland", "Portland", "Pennsylvania", "Pakistan", "Israel",
"Mumbai, India", "Kenya", "Bangkok, Thailand", "Los Angeles",
"Cape Town, South Africa", "Tokyo, Japan", "Manila, Philippines", "New Orleans",
"Jakarta, Indonesia", "Mexico City, Mexico", "Bengaluru, India", "San Francisco",
"Nairobi, Kenya", "Kolkata, India", "Caribbean Islands", "Southeast Asia",
"California", "New York", "Bangladesh", "Sri Lanka", "Vietnam", "Cambodia",
"Thailand", "Myanmar", "Nepal", "Tanzania", "Ethiopia", "Ghana", "Uganda",
"South Korea", "Taiwan", "Singapore", "New Zealand", "Fiji", "Samoa", "Tonga"]) for _ in range(len(new_tweets))],
    'id': [i for i in range(len(new_tweets))],
    'keyword': [np.random.choice(disaster_keywords) for _ in range(len(new_tweets))]
})
# Merge new_df with df_merged
df_merged = pd.concat([df_merged, new_df2], ignore_index=True)

# Reset index
df_merged.reset_index(drop=True, inplace=True)

df_merged.shape

df_merged['target'].value_counts()

df_merged.to_csv('Twitter_data.csv', index=False)

crop_map = {
    'Rice': 'PADDY',
    'Jowar': 'JOWAR',
    'Bajra': 'BAJRA',
    'Ragi': 'RAGI',
    'Small millets': 'SMALL MILLETS',
    'Barley': 'BARLEY',
    'Sesamum': 'SESAME',
    'Linseed': 'LINSEED',
    'Castor seed': 'CASTOR',
    'Safflower': 'SAFFLOWER',
    'Niger seed': 'NIGER',
    'Sunflower': 'SUNFLOWER',
    'Soyabean': 'SOYBEAN',
    'Coconut': 'COCONUT',
    'Cotton seed': 'COTTON SEED',
    'Jute': 'JUTE',
    'Mesta': 'MESTA',
    'Tea': 'TEA',
    'Coffee': 'COFFEE',
    'Rubber': 'RUBBER',
    'Black pepper': 'BLACK PEPPER',
    'Dry chilies': 'DRY CHILIES',
    'Dry ginger': 'DRY GINGER',
    'Turmeric': 'TURMERIC',
    'Arecanut': 'ARECANUT',
    'Cardamom': 'CARDAMOM',
    'Coriander': 'CORIANDER',
    'Garlic': 'GARLIC',
    'Potato': 'POTATO',
    'Tapioca': 'TAPIOCA',
    'Sweet potato': 'SWEET POTATO',
    'Onion': 'ONION',
    'Banana': 'BANANA',
    'Tobacco': 'TOBACCO'
}

# Define function to extract crop
def extract_crop(Particulars):
    crop_types = ['Rice', 'Wheat', 'Maize', 'Jowar', 'Bajra', 'Gram', 'Tur', 'Groundnut', 'Soyabean', 'Sunflower',
                  'Coarse Cereals', 'Pulses', 'Oilseeds', 'Cotton', 'Jute', 'Mesta', 'Sugarcane', 'Potato',
                  'Onion', 'Tobacco', 'Coconut', 'Cashewnut', 'Barley', 'Ragi', 'Small Millets', 'Castorseed',
                  'Sesamun', 'Nigerseed', 'Rapeseed', 'Mustard', 'Linseed', 'Safflower']
    Particulars = Particulars.lower()  # Convert to lowercase
    for crop in crop_types:
        if crop in Particulars:
            return crop
    return None

# Extract crop and fill null values in Crop column
df_merged.loc[df_merged['Crop'].isnull(), 'Crop'] = df_merged.loc[df_merged['Crop'].isnull(), 'Particulars'].apply(extract_crop)